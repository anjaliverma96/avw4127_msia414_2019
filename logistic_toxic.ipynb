{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score,precision_score, recall_score, hamming_loss\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.read_csv(\"toxic_comments_cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(toxic_comments['clean_comment_text'], y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_toxic = TfidfVectorizer(analyzer = 'word', max_df=0.8, max_features=10000)\n",
    "# Dump the file\n",
    "pickle.dump(tfidf_vectorizer_toxic, open(\"tfidf_vectorizer_toxic.pkl\", \"wb\"))\n",
    "#load saved tfidfvectorizer\n",
    "tfidf_vectorizer_toxic = pickle.load(open(\"tfidf_vectorizer_toxic.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer_toxic.fit_transform(xtrain.values.astype('U'))\n",
    "xval_tfidf = tfidf_vectorizer_toxic.transform(xval.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing  0.01 newton-cg\n",
      "curr_score  0.9016449945166849\n",
      "best_params  [0.01, 'newton-cg']\n",
      "\n",
      "Doing  0.01 lbfgs\n",
      "curr_score  0.9016449945166849\n",
      "best_params  [0.01, 'newton-cg']\n",
      "\n",
      "Doing  0.01 liblinear\n",
      "curr_score  0.9017076609744634\n",
      "best_params  [0.01, 'liblinear']\n",
      "\n",
      "Doing  0.01 saga\n",
      "curr_score  0.9016449945166849\n",
      "best_params  [0.01, 'liblinear']\n",
      "\n",
      "Doing  0.01 sag\n",
      "curr_score  0.9016449945166849\n",
      "best_params  [0.01, 'liblinear']\n",
      "\n",
      "Doing  1 newton-cg\n",
      "curr_score  0.9216669277769074\n",
      "best_params  [1, 'newton-cg']\n",
      "\n",
      "Doing  1 lbfgs\n",
      "curr_score  0.9216669277769074\n",
      "best_params  [1, 'newton-cg']\n",
      "\n",
      "Doing  1 liblinear\n",
      "curr_score  0.9216669277769074\n",
      "best_params  [1, 'newton-cg']\n",
      "\n",
      "Doing  1 saga\n",
      "curr_score  0.9216982610057967\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  1 sag\n",
      "curr_score  0.9216669277769074\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  10 newton-cg\n",
      "curr_score  0.920162932790224\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  10 lbfgs\n",
      "curr_score  0.9201002663324456\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  10 liblinear\n",
      "curr_score  0.920162932790224\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  10 saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_score  0.9202255992480025\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  10 sag\n",
      "curr_score  0.920162932790224\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  100 newton-cg\n",
      "curr_score  0.9110449631834561\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  100 lbfgs\n",
      "curr_score  0.9122356258812471\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  100 liblinear\n",
      "curr_score  0.9111076296412345\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  100 saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_score  0.911828293905687\n",
      "best_params  [1, 'saga']\n",
      "\n",
      "Doing  100 sag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_score  0.9110136299545668\n",
      "best_params  [1, 'saga']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "score = 0\n",
    "best_param = [0,0]\n",
    "scores = {'newton-cg':[],'lbfgs':[],'liblinear':[],'saga':[],'sag':[]}\n",
    "for c in [0.01, 1, 10, 100]:\n",
    "    for s in ('newton-cg', 'lbfgs', 'liblinear','saga','sag'):\n",
    "        print('Doing ',c, s)\n",
    "        lr = LogisticRegression(C=c, solver = s,penalty = 'l2')\n",
    "        clf = OneVsRestClassifier(lr)\n",
    "        clf.fit(xtrain_tfidf, ytrain)\n",
    "        y_pred = clf.predict(xval_tfidf)\n",
    "        test_accuracy = accuracy_score(yval, y_pred)\n",
    "        test_precision = precision_score(yval, y_pred, average = \"micro\")\n",
    "        test_recall = recall_score(yval, y_pred, average = \"micro\")\n",
    "        test_f1_score = f1_score(yval, y_pred, average = \"micro\")\n",
    "        hamming_score = hamming_loss(yval, y_pred)\n",
    "        val_score = clf.score(xval_tfidf,yval)\n",
    "        if val_score > score:\n",
    "            score = val_score\n",
    "            best_param[0] = c\n",
    "            best_param[1] = s\n",
    "        print('curr_score ',val_score)\n",
    "        scores[s].append((c,val_score, test_accuracy, test_precision, test_recall, test_f1_score, hamming_score))\n",
    "        print('best_params ',best_param)\n",
    "        print('')\n",
    "                                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'newton-cg': [(0.01,\n",
       "   0.9016449945166849,\n",
       "   0.9016449945166849,\n",
       "   0.9740518962075848,\n",
       "   0.07035755478662054,\n",
       "   0.13123571332526557,\n",
       "   0.033740665308893414),\n",
       "  (1,\n",
       "   0.9216669277769074,\n",
       "   0.9216669277769074,\n",
       "   0.8754725372470535,\n",
       "   0.5676182237600923,\n",
       "   0.6887081256013294,\n",
       "   0.018585826936132435),\n",
       "  (10,\n",
       "   0.920162932790224,\n",
       "   0.920162932790224,\n",
       "   0.8225594903503841,\n",
       "   0.6329296424452133,\n",
       "   0.7153915098183004,\n",
       "   0.01824116141835083),\n",
       "  (100,\n",
       "   0.9110449631834561,\n",
       "   0.9110449631834561,\n",
       "   0.7623302973019419,\n",
       "   0.6395617070357554,\n",
       "   0.6955703645629164,\n",
       "   0.020277821296151233)],\n",
       " 'lbfgs': [(0.01,\n",
       "   0.9016449945166849,\n",
       "   0.9016449945166849,\n",
       "   0.9740518962075848,\n",
       "   0.07035755478662054,\n",
       "   0.13123571332526557,\n",
       "   0.033740665308893414),\n",
       "  (1,\n",
       "   0.9216669277769074,\n",
       "   0.9216669277769074,\n",
       "   0.8754725372470535,\n",
       "   0.5676182237600923,\n",
       "   0.6887081256013294,\n",
       "   0.018585826936132435),\n",
       "  (10,\n",
       "   0.9201002663324456,\n",
       "   0.9201002663324456,\n",
       "   0.8221432579016271,\n",
       "   0.6337946943483276,\n",
       "   0.7157860457542945,\n",
       "   0.018230717008721083),\n",
       "  (100,\n",
       "   0.9122356258812471,\n",
       "   0.9122356258812471,\n",
       "   0.7662828664719024,\n",
       "   0.6428777393310265,\n",
       "   0.6991767934143474,\n",
       "   0.020037599874667085)],\n",
       " 'liblinear': [(0.01,\n",
       "   0.9017076609744634,\n",
       "   0.9017076609744634,\n",
       "   0.9747081712062257,\n",
       "   0.0722318339100346,\n",
       "   0.134496644295302,\n",
       "   0.03367277664630007),\n",
       "  (1,\n",
       "   0.9216669277769074,\n",
       "   0.9216669277769074,\n",
       "   0.8756395995550612,\n",
       "   0.5674740484429066,\n",
       "   0.6886536610970169,\n",
       "   0.018585826936132435),\n",
       "  (10,\n",
       "   0.920162932790224,\n",
       "   0.920162932790224,\n",
       "   0.8225594903503841,\n",
       "   0.6329296424452133,\n",
       "   0.7153915098183004,\n",
       "   0.01824116141835083),\n",
       "  (100,\n",
       "   0.9111076296412345,\n",
       "   0.9111076296412345,\n",
       "   0.7625021481354185,\n",
       "   0.6397058823529411,\n",
       "   0.6957271658173264,\n",
       "   0.02026737688652149)],\n",
       " 'saga': [(0.01,\n",
       "   0.9016449945166849,\n",
       "   0.9016449945166849,\n",
       "   0.9741035856573705,\n",
       "   0.07050173010380623,\n",
       "   0.13148695885990855,\n",
       "   0.03373544310407854),\n",
       "  (1,\n",
       "   0.9216982610057967,\n",
       "   0.9216982610057967,\n",
       "   0.8758344459279038,\n",
       "   0.5674740484429066,\n",
       "   0.6887139107611548,\n",
       "   0.018580604731317563),\n",
       "  (10,\n",
       "   0.9202255992480025,\n",
       "   0.9202255992480025,\n",
       "   0.8229342327150084,\n",
       "   0.6332179930795848,\n",
       "   0.7157174285015889,\n",
       "   0.018220272599091335),\n",
       "  (100,\n",
       "   0.911828293905687,\n",
       "   0.911828293905687,\n",
       "   0.7672012415933782,\n",
       "   0.6414359861591695,\n",
       "   0.6987043580683157,\n",
       "   0.020037599874667085)],\n",
       " 'sag': [(0.01,\n",
       "   0.9016449945166849,\n",
       "   0.9016449945166849,\n",
       "   0.9740518962075848,\n",
       "   0.07035755478662054,\n",
       "   0.13123571332526557,\n",
       "   0.033740665308893414),\n",
       "  (1,\n",
       "   0.9216669277769074,\n",
       "   0.9216669277769074,\n",
       "   0.8754725372470535,\n",
       "   0.5676182237600923,\n",
       "   0.6887081256013294,\n",
       "   0.018585826936132435),\n",
       "  (10,\n",
       "   0.920162932790224,\n",
       "   0.920162932790224,\n",
       "   0.8225594903503841,\n",
       "   0.6329296424452133,\n",
       "   0.7153915098183004,\n",
       "   0.01824116141835083),\n",
       "  (100,\n",
       "   0.9110136299545668,\n",
       "   0.9110136299545668,\n",
       "   0.7622401649201168,\n",
       "   0.6397058823529411,\n",
       "   0.6956180920279061,\n",
       "   0.020277821296151233)]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg\n",
      "(0.01, 0.9016449945166849, 0.9016449945166849, 0.9740518962075848, 0.07035755478662054, 0.13123571332526557, 0.033740665308893414)\n",
      "(1, 0.9216669277769074, 0.9216669277769074, 0.8754725372470535, 0.5676182237600923, 0.6887081256013294, 0.018585826936132435)\n",
      "(10, 0.920162932790224, 0.920162932790224, 0.8225594903503841, 0.6329296424452133, 0.7153915098183004, 0.01824116141835083)\n",
      "(100, 0.9110449631834561, 0.9110449631834561, 0.7623302973019419, 0.6395617070357554, 0.6955703645629164, 0.020277821296151233)\n",
      "lbfgs\n",
      "(0.01, 0.9016449945166849, 0.9016449945166849, 0.9740518962075848, 0.07035755478662054, 0.13123571332526557, 0.033740665308893414)\n",
      "(1, 0.9216669277769074, 0.9216669277769074, 0.8754725372470535, 0.5676182237600923, 0.6887081256013294, 0.018585826936132435)\n",
      "(10, 0.9201002663324456, 0.9201002663324456, 0.8221432579016271, 0.6337946943483276, 0.7157860457542945, 0.018230717008721083)\n",
      "(100, 0.9122356258812471, 0.9122356258812471, 0.7662828664719024, 0.6428777393310265, 0.6991767934143474, 0.020037599874667085)\n",
      "liblinear\n",
      "(0.01, 0.9017076609744634, 0.9017076609744634, 0.9747081712062257, 0.0722318339100346, 0.134496644295302, 0.03367277664630007)\n",
      "(1, 0.9216669277769074, 0.9216669277769074, 0.8756395995550612, 0.5674740484429066, 0.6886536610970169, 0.018585826936132435)\n",
      "(10, 0.920162932790224, 0.920162932790224, 0.8225594903503841, 0.6329296424452133, 0.7153915098183004, 0.01824116141835083)\n",
      "(100, 0.9111076296412345, 0.9111076296412345, 0.7625021481354185, 0.6397058823529411, 0.6957271658173264, 0.02026737688652149)\n",
      "saga\n",
      "(0.01, 0.9016449945166849, 0.9016449945166849, 0.9741035856573705, 0.07050173010380623, 0.13148695885990855, 0.03373544310407854)\n",
      "(1, 0.9216982610057967, 0.9216982610057967, 0.8758344459279038, 0.5674740484429066, 0.6887139107611548, 0.018580604731317563)\n",
      "(10, 0.9202255992480025, 0.9202255992480025, 0.8229342327150084, 0.6332179930795848, 0.7157174285015889, 0.018220272599091335)\n",
      "(100, 0.911828293905687, 0.911828293905687, 0.7672012415933782, 0.6414359861591695, 0.6987043580683157, 0.020037599874667085)\n",
      "sag\n",
      "(0.01, 0.9016449945166849, 0.9016449945166849, 0.9740518962075848, 0.07035755478662054, 0.13123571332526557, 0.033740665308893414)\n",
      "(1, 0.9216669277769074, 0.9216669277769074, 0.8754725372470535, 0.5676182237600923, 0.6887081256013294, 0.018585826936132435)\n",
      "(10, 0.920162932790224, 0.920162932790224, 0.8225594903503841, 0.6329296424452133, 0.7153915098183004, 0.01824116141835083)\n",
      "(100, 0.9110136299545668, 0.9110136299545668, 0.7622401649201168, 0.6397058823529411, 0.6956180920279061, 0.020277821296151233)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([0,0,0,0,0,0])\n",
    "for i in scores:\n",
    "    print(i)\n",
    "    for inte in scores[i]:\n",
    "        \n",
    "        print(inte)\n",
    "#         print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing  0.1 newton-cg\n",
      "curr_score  0.9128622904590318\n",
      "best_params  [0.1, 'newton-cg']\n",
      "\n",
      "Doing  0.1 lbfgs\n",
      "curr_score  0.9128622904590318\n",
      "best_params  [0.1, 'newton-cg']\n",
      "\n",
      "Doing  0.1 liblinear\n",
      "curr_score  0.9128622904590318\n",
      "best_params  [0.1, 'newton-cg']\n",
      "\n",
      "Doing  0.1 saga\n",
      "curr_score  0.9128622904590318\n",
      "best_params  [0.1, 'newton-cg']\n",
      "\n",
      "Doing  0.1 sag\n",
      "curr_score  0.9128622904590318\n",
      "best_params  [0.1, 'newton-cg']\n",
      "\n",
      "Doing  0.575 newton-cg\n",
      "curr_score  0.920037599874667\n",
      "best_params  [0.575, 'newton-cg']\n",
      "\n",
      "Doing  0.575 lbfgs\n",
      "curr_score  0.920037599874667\n",
      "best_params  [0.575, 'newton-cg']\n",
      "\n",
      "Doing  0.575 liblinear\n",
      "curr_score  0.920037599874667\n",
      "best_params  [0.575, 'newton-cg']\n",
      "\n",
      "Doing  0.575 saga\n",
      "curr_score  0.9200689331035563\n",
      "best_params  [0.575, 'saga']\n",
      "\n",
      "Doing  0.575 sag\n",
      "curr_score  0.920037599874667\n",
      "best_params  [0.575, 'saga']\n",
      "\n",
      "Doing  1.05 newton-cg\n",
      "curr_score  0.9217922606924643\n",
      "best_params  [1.05, 'newton-cg']\n",
      "\n",
      "Doing  1.05 lbfgs\n",
      "curr_score  0.9217922606924643\n",
      "best_params  [1.05, 'newton-cg']\n",
      "\n",
      "Doing  1.05 liblinear\n",
      "curr_score  0.9217609274635751\n",
      "best_params  [1.05, 'newton-cg']\n",
      "\n",
      "Doing  1.05 saga\n",
      "curr_score  0.9217609274635751\n",
      "best_params  [1.05, 'newton-cg']\n",
      "\n",
      "Doing  1.05 sag\n",
      "curr_score  0.9217922606924643\n",
      "best_params  [1.05, 'newton-cg']\n",
      "\n",
      "Doing  1.525 newton-cg\n",
      "curr_score  0.9220115932946891\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  1.525 lbfgs\n",
      "curr_score  0.9220115932946891\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  1.525 liblinear\n",
      "curr_score  0.9220115932946891\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  1.525 saga\n",
      "curr_score  0.9219802600657998\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  1.525 sag\n",
      "curr_score  0.9220115932946891\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  2.0 newton-cg\n",
      "curr_score  0.9219175936080213\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  2.0 lbfgs\n",
      "curr_score  0.9219175936080213\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  2.0 liblinear\n",
      "curr_score  0.9219489268369105\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  2.0 saga\n",
      "curr_score  0.9218235939213536\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n",
      "Doing  2.0 sag\n",
      "curr_score  0.9219175936080213\n",
      "best_params  [1.525, 'newton-cg']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reducing hyperparam search to 1 to 9 in steps of 1\n",
    "import time\n",
    "score = 0\n",
    "best_param_2 = [0,0]\n",
    "scores_2 = {'newton-cg':[],'lbfgs':[],'liblinear':[],'saga':[],'sag':[]}\n",
    "for c in np.linspace(0.1,2,5):\n",
    "    for s in ('newton-cg', 'lbfgs', 'liblinear','saga','sag'):\n",
    "        print('Doing ',c, s)\n",
    "        time_start=time.time()\n",
    "        lr = LogisticRegression(C=c, solver = s,penalty = 'l2', max_iter = 1000)\n",
    "        clf = OneVsRestClassifier(lr)\n",
    "        clf.fit(xtrain_tfidf, ytrain)\n",
    "        y_pred = clf.predict(xval_tfidf)\n",
    "        test_accuracy = accuracy_score(yval, y_pred)\n",
    "        test_precision = precision_score(yval, y_pred, average = \"micro\")\n",
    "        test_recall = recall_score(yval, y_pred, average = \"micro\")\n",
    "        test_f1_score = f1_score(yval, y_pred, average = \"micro\")\n",
    "        hamming_score = hamming_loss(yval, y_pred)\n",
    "        val_score = clf.score(xval_tfidf,yval)\n",
    "        if val_score > score:\n",
    "            score = val_score\n",
    "            best_param[0] = c\n",
    "            best_param[1] = s\n",
    "        print('curr_score ',val_score)\n",
    "        scores_2[s].append((c,val_score, test_accuracy, test_precision, test_recall, test_f1_score, hamming_score))\n",
    "        print('best_params ',best_param)\n",
    "        print('')                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg\n",
      "(0.1, 0.9128622904590318, 0.9128622904590318, 0.9325546345139413, 0.3568339100346021, 0.5161626694473409, 0.024231030341009974)\n",
      "(0.575, 0.920037599874667, 0.920037599874667, 0.8896969696969697, 0.529123414071511, 0.6635928035439833, 0.019431824116141836)\n",
      "(1.05, 0.9217922606924643, 0.9217922606924643, 0.875082909573292, 0.5706459054209919, 0.6908107164674056, 0.01850227165909447)\n",
      "(1.525, 0.9220115932946891, 0.9220115932946891, 0.8654336734693877, 0.5869377162629758, 0.6994845360824741, 0.01826727244242519)\n",
      "(2.0, 0.9219175936080213, 0.9219175936080213, 0.8573495968575563, 0.5978950403690888, 0.7044933322007984, 0.01816805055094261)\n",
      "lbfgs\n",
      "(0.1, 0.9128622904590318, 0.9128622904590318, 0.9325546345139413, 0.3568339100346021, 0.5161626694473409, 0.024231030341009974)\n",
      "(0.575, 0.920037599874667, 0.920037599874667, 0.8896969696969697, 0.529123414071511, 0.6635928035439833, 0.019431824116141836)\n",
      "(1.05, 0.9217922606924643, 0.9217922606924643, 0.875082909573292, 0.5706459054209919, 0.6908107164674056, 0.01850227165909447)\n",
      "(1.525, 0.9220115932946891, 0.9220115932946891, 0.8654336734693877, 0.5869377162629758, 0.6994845360824741, 0.01826727244242519)\n",
      "(2.0, 0.9219175936080213, 0.9219175936080213, 0.8573495968575563, 0.5978950403690888, 0.7044933322007984, 0.01816805055094261)\n",
      "liblinear\n",
      "(0.1, 0.9128622904590318, 0.9128622904590318, 0.9325800376647835, 0.35697808535178777, 0.5163173808779065, 0.024225808136195102)\n",
      "(0.575, 0.920037599874667, 0.920037599874667, 0.8895348837209303, 0.5294117647058824, 0.6637744034707158, 0.019426601911326963)\n",
      "(1.05, 0.9217609274635751, 0.9217609274635751, 0.8750552852720035, 0.5705017301038062, 0.6906964566241927, 0.018507493863909343)\n",
      "(1.525, 0.9220115932946891, 0.9220115932946891, 0.8652497343251859, 0.5869377162629758, 0.6994244480714714, 0.018272494647240064)\n",
      "(2.0, 0.9219489268369105, 0.9219489268369105, 0.8575563365722555, 0.5980392156862745, 0.7046632124352331, 0.018157606141312864)\n",
      "saga\n",
      "(0.1, 0.9128622904590318, 0.9128622904590318, 0.9325546345139413, 0.3568339100346021, 0.5161626694473409, 0.024231030341009974)\n",
      "(0.575, 0.9200689331035563, 0.9200689331035563, 0.8895616372002906, 0.529555940023068, 0.6638951649344781, 0.01942137970651209)\n",
      "(1.05, 0.9217609274635751, 0.9217609274635751, 0.8750552852720035, 0.5705017301038062, 0.6906964566241927, 0.018507493863909343)\n",
      "(1.525, 0.9219802600657998, 0.9219802600657998, 0.8652210884353742, 0.5867935409457901, 0.6993127147766324, 0.018277716852054936)\n",
      "(2.0, 0.9218235939213536, 0.9218235939213536, 0.8567589913187268, 0.5976066897347174, 0.7040937659249193, 0.018194161575016972)\n",
      "sag\n",
      "(0.1, 0.9128622904590318, 0.9128622904590318, 0.9325546345139413, 0.3568339100346021, 0.5161626694473409, 0.024231030341009974)\n",
      "(0.575, 0.920037599874667, 0.920037599874667, 0.8896969696969697, 0.529123414071511, 0.6635928035439833, 0.019431824116141836)\n",
      "(1.05, 0.9217922606924643, 0.9217922606924643, 0.875082909573292, 0.5706459054209919, 0.6908107164674056, 0.01850227165909447)\n",
      "(1.525, 0.9220115932946891, 0.9220115932946891, 0.8654336734693877, 0.5869377162629758, 0.6994845360824741, 0.01826727244242519)\n",
      "(2.0, 0.9219175936080213, 0.9219175936080213, 0.8573495968575563, 0.5978950403690888, 0.7044933322007984, 0.01816805055094261)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([0,0,0,0,0,0])\n",
    "for i in scores_2:\n",
    "    print(i)\n",
    "    for inte in scores_2[i]:\n",
    "        \n",
    "        print(inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing  0.1 liblinear\n",
      "curr_score  0.9176876077079743\n",
      "best_params  [0.1, 'liblinear']\n",
      "timetaken  2.7865772247314453\n",
      "\n",
      "Doing  0.1 saga\n",
      "curr_score  0.9176876077079743\n",
      "best_params  [0.1, 'liblinear']\n",
      "timetaken  11.506447076797485\n",
      "\n",
      "Doing  0.575 liblinear\n",
      "curr_score  0.922262259125803\n",
      "best_params  [0.575, 'liblinear']\n",
      "timetaken  4.057555913925171\n",
      "\n",
      "Doing  0.575 saga\n",
      "curr_score  0.922262259125803\n",
      "best_params  [0.575, 'liblinear']\n",
      "timetaken  80.42394804954529\n",
      "\n",
      "Doing  1.05 liblinear\n",
      "curr_score  0.922418925270249\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  5.607601881027222\n",
      "\n",
      "Doing  1.05 saga\n",
      "curr_score  0.922418925270249\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  277.05101799964905\n",
      "\n",
      "Doing  1.525 liblinear\n",
      "curr_score  0.9214162619457935\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  5.464899778366089\n",
      "\n",
      "Doing  1.525 saga\n",
      "curr_score  0.9214162619457935\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  465.5364520549774\n",
      "\n",
      "Doing  2.0 liblinear\n",
      "curr_score  0.9212595958013473\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  5.917608261108398\n",
      "\n",
      "Doing  2.0 saga\n",
      "curr_score  0.921228262572458\n",
      "best_params  [1.05, 'liblinear']\n",
      "timetaken  881.4115040302277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reducing hyperparam search to 1 to 5 in steps of 1\n",
    "import time\n",
    "score = 0\n",
    "best_param_2 = [0,0]\n",
    "scores_3 = {'liblinear':[],'saga':[]}\n",
    "for c in np.linspace(0.1,2,5):\n",
    "    for s in ('liblinear','saga'):\n",
    "        print('Doing ',c, s)\n",
    "        time_start=time.time()\n",
    "        lr = LogisticRegression(C=c, solver = s,penalty = 'l1', max_iter = 1000)\n",
    "        clf = OneVsRestClassifier(lr)\n",
    "        clf.fit(xtrain_tfidf, ytrain)\n",
    "        y_pred = clf.predict(xval_tfidf)\n",
    "        test_accuracy = accuracy_score(yval, y_pred)\n",
    "        test_precision = precision_score(yval, y_pred, average = \"micro\")\n",
    "        test_recall = recall_score(yval, y_pred, average = \"micro\")\n",
    "        test_f1_score = f1_score(yval, y_pred, average = \"micro\")\n",
    "        hamming_score = hamming_loss(yval, y_pred)\n",
    "        val_score = clf.score(xval_tfidf,yval)\n",
    "        if val_score > score:\n",
    "            score = val_score\n",
    "            best_param[0] = c\n",
    "            best_param[1] = s\n",
    "        print('curr_score ',val_score)\n",
    "        scores_3[s].append((c,val_score, test_accuracy, test_precision, test_recall, test_f1_score, hamming_score))\n",
    "        print('best_params ',best_param)\n",
    "        timetaken = time.time()-time_start\n",
    "        print('timetaken ',timetaken)\n",
    "        print('')                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "(0.1, 0.9176876077079743, 0.9176876077079743, 0.8812211390456645, 0.495242214532872, 0.6341148237031567, 0.020700819886155936)\n",
      "(0.575, 0.922262259125803, 0.922262259125803, 0.8536585365853658, 0.6055363321799307, 0.708502024291498, 0.018047939840200533)\n",
      "(1.05, 0.922418925270249, 0.922418925270249, 0.8453244461870222, 0.621683967704729, 0.7164575891002741, 0.017823385033161)\n",
      "(1.525, 0.9214162619457935, 0.9214162619457935, 0.8355351330652881, 0.6291810841983853, 0.71782218932478, 0.017917384719828712)\n",
      "(2.0, 0.9212595958013473, 0.9212595958013473, 0.8297149329809326, 0.6336505190311419, 0.7185481893239598, 0.017980051177607186)\n",
      "saga\n",
      "(0.1, 0.9176876077079743, 0.9176876077079743, 0.8812516029751218, 0.4953863898500577, 0.6342408860175357, 0.020695597681341063)\n",
      "(0.575, 0.922262259125803, 0.922262259125803, 0.8536585365853658, 0.6055363321799307, 0.708502024291498, 0.018047939840200533)\n",
      "(1.05, 0.922418925270249, 0.922418925270249, 0.8453244461870222, 0.621683967704729, 0.7164575891002741, 0.017823385033161)\n",
      "(1.525, 0.9214162619457935, 0.9214162619457935, 0.8355351330652881, 0.6291810841983853, 0.71782218932478, 0.017917384719828712)\n",
      "(2.0, 0.921228262572458, 0.921228262572458, 0.8295583238958097, 0.6336505190311419, 0.7184894556154977, 0.01798527338242206)\n"
     ]
    }
   ],
   "source": [
    "for i in scores_3:\n",
    "    print(i)\n",
    "    for inte in scores_3[i]:\n",
    "        print(inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'liblinear': [], 'saga': []}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer = 'word', max_df=0.75, max_features=10000, ngram_range=(1,3))\n",
    "# Dump the file\n",
    "pickle.dump(tfidf_vect_ngram_toxic, open(\"tfidf_vect_ngram_toxic.pkl\", \"wb\"))\n",
    "#load saved tfidfvectorizer\n",
    "tfidf_vect_ngram_toxic = pickle.load(open(\"tfidf_vect_ngram_toxic.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF features\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.fit_transform(xtrain.values.astype('U'))\n",
    "xval_tfidf_ngram = tfidf_vect_ngram.transform(xval.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing hyperparam search to 1 to 5 in steps of 1\n",
    "import time\n",
    "score = 0\n",
    "best_param_2 = [0,0]\n",
    "scores_2 = {'liblinear':[],'saga':[]}\n",
    "for c in range(1,5):\n",
    "    for s in ('liblinear','saga'):\n",
    "        print('Doing ',c, s)\n",
    "        time_start=time.time()\n",
    "        lr = LogisticRegression(C=c, solver = s,penalty = 'l1', max_iter = 1000)\n",
    "        clf = OneVsRestClassifier(lr)\n",
    "        clf.fit(xtrain_tfidf_ngram, ytrain)\n",
    "        y_pred = clf.predict(xval_tfidf_ngram)\n",
    "        test_accuracy = accuracy_score(yval, y_pred)\n",
    "        test_precision = precision_score(yval, y_pred, average = \"micro\")\n",
    "        test_recall = recall_score(yval, y_pred, average = \"micro\")\n",
    "        test_f1_score = f1_score(yval, y_pred, average = \"micro\")\n",
    "        hamming_score = hamming_loss(yval, y_pred)\n",
    "        val_score = clf.score(xval_tfidf,yval)\n",
    "        if val_score > score:\n",
    "            score = val_score\n",
    "            best_param[0] = c\n",
    "            best_param[1] = s\n",
    "        print('curr_score ',val_score)\n",
    "        scores[s].append((c,val_score, test_accuracy, test_precision, test_recall, test_f1_score, hamming_score))\n",
    "        print('best_params ',best_param)\n",
    "        print('')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #reducing hyperparam space to 1 to 3\n",
    "# score = 0\n",
    "# best_param_3 = [0,0]\n",
    "# scores_3 = {'newton-cg':[],'lbfgs':[],'liblinear':[],'saga':[],'sag':[]}\n",
    "# for c in np.linspace(1.1,3,20):\n",
    "#     for s in ('newton-cg', 'lbfgs', 'liblinear','saga','sag'):\n",
    "#         print('Doing ',c, s)\n",
    "#         time_start=time.time()\n",
    "#         lr = LogisticRegression(C=c, solver = s,penalty = 'l2', max_iter = 1000)\n",
    "#         clf = OneVsRestClassifier(lr)\n",
    "#         clf.fit(xtrain_tfidf, ytrain)\n",
    "#         y_pred = clf.predict(xval_tfidf)\n",
    "#         test_accuracy = accuracy_score(yval, y_pred)\n",
    "#         test_precision = precision_score(yval, y_pred, average = \"micro\")\n",
    "#         test_recall = recall_score(yval, y_pred, average = \"micro\")\n",
    "#         test_f1_score = f1_score(yval, y_pred, average = \"micro\")\n",
    "#         hamming_score = hamming_loss(yval, y_pred)\n",
    "#         val_score = clf.score(xval_tfidf,yval)\n",
    "#         if val_score > score:\n",
    "#             score = val_score\n",
    "#             best_param[0] = c\n",
    "#             best_param[1] = s\n",
    "#         print('curr_score ',val_score)\n",
    "#         scores[s].append((c,val_score, test_accuracy, test_precision, test_recall, test_f1_score, hamming_score))\n",
    "#         print('best_params ',best_param)\n",
    "#         print('')       \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
